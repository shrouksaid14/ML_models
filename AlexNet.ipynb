{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sna0nBaPoGu",
        "outputId": "1dfc4566-33fc-493d-c589-48f95da0f893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split_folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CMeDHBDP0YY",
        "outputId": "f385c9a7-0a21-4857-8ffc-07547d084b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split_folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_folder='/content/drive/MyDrive/sprints project /Scenes training set'\n",
        "import splitfolders\n",
        "splitfolders.ratio(img_folder, output=\"output\",\n",
        "    seed=1337, ratio=(.7,0.3), group_prefix=None, move=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZD3aTOTP0c_",
        "outputId": "16977f78-c5cd-4e2e-a7d3-438cf1352922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 14034 files [04:50, 48.31 files/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/output/train'\n",
        "val_dir = '/content/output/val'\n",
        "test_dir = '/content/drive/MyDrive/sprints project /testset'"
      ],
      "metadata": {
        "id": "yLF_DyRgP0fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        " \n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        " \n",
        "val_set = val_datagen.flow_from_directory(val_dir,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory(test_dir,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            shuffle=False,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqyKcPxP0iY",
        "outputId": "03ee0661-54a4-4b24-b231-07cf1d1d3a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9820 images belonging to 6 classes.\n",
            "Found 4214 images belonging to 6 classes.\n",
            "Found 3050 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "AlexNet = Sequential()\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(224,224,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(6))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-NAjC7yP0m3",
        "outputId": "0ec59085-ee70-4543-d2a6-540ae8f0e34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 56, 56, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 56, 56, 96)       384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 56, 56, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 28, 28, 96)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 28, 28, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 28, 28, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 14, 14, 384)       885120    \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 14, 14, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 14, 14, 384)       0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 14, 14, 384)       1327488   \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 14, 14, 384)      1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 14, 14, 384)       0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 14, 14, 256)       884992    \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 14, 14, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 14, 14, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 7, 7, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 4096)              51384320  \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 1000)             4000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 1000)              0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 6)                 6006      \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 6)                24        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76,058,134\n",
            "Trainable params: 76,036,986\n",
            "Non-trainable params: 21,148\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Uvauv4dRrpct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet.fit(training_set,\n",
        "          batch_size=128,\n",
        "          epochs=25,\n",
        "          verbose=1,\n",
        "          validation_data=val_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUmXLSTTP0pX",
        "outputId": "d9d73a6c-0c5f-427b-81b4-9206ac77afa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "307/307 [==============================] - 191s 401ms/step - loss: 1.0447 - accuracy: 0.6213 - val_loss: 1.5279 - val_accuracy: 0.4535\n",
            "Epoch 2/25\n",
            "307/307 [==============================] - 120s 392ms/step - loss: 0.8376 - accuracy: 0.7137 - val_loss: 2.0129 - val_accuracy: 0.3640\n",
            "Epoch 3/25\n",
            "307/307 [==============================] - 119s 387ms/step - loss: 0.7286 - accuracy: 0.7557 - val_loss: 1.9729 - val_accuracy: 0.3446\n",
            "Epoch 4/25\n",
            "307/307 [==============================] - 121s 395ms/step - loss: 0.6757 - accuracy: 0.7740 - val_loss: 1.4781 - val_accuracy: 0.4922\n",
            "Epoch 5/25\n",
            "307/307 [==============================] - 119s 388ms/step - loss: 0.6164 - accuracy: 0.7941 - val_loss: 1.0605 - val_accuracy: 0.6125\n",
            "Epoch 6/25\n",
            "307/307 [==============================] - 120s 390ms/step - loss: 0.5981 - accuracy: 0.7988 - val_loss: 1.1634 - val_accuracy: 0.5942\n",
            "Epoch 7/25\n",
            "307/307 [==============================] - 118s 385ms/step - loss: 0.5493 - accuracy: 0.8148 - val_loss: 0.7395 - val_accuracy: 0.7342\n",
            "Epoch 8/25\n",
            "307/307 [==============================] - 118s 386ms/step - loss: 0.5162 - accuracy: 0.8260 - val_loss: 0.9413 - val_accuracy: 0.6561\n",
            "Epoch 9/25\n",
            "307/307 [==============================] - 118s 386ms/step - loss: 0.4946 - accuracy: 0.8330 - val_loss: 3.0549 - val_accuracy: 0.3412\n",
            "Epoch 10/25\n",
            "307/307 [==============================] - 117s 382ms/step - loss: 0.4811 - accuracy: 0.8394 - val_loss: 0.7739 - val_accuracy: 0.7326\n",
            "Epoch 11/25\n",
            "307/307 [==============================] - 118s 385ms/step - loss: 0.4540 - accuracy: 0.8476 - val_loss: 1.0695 - val_accuracy: 0.6312\n",
            "Epoch 12/25\n",
            "307/307 [==============================] - 117s 383ms/step - loss: 0.4413 - accuracy: 0.8469 - val_loss: 0.4748 - val_accuracy: 0.8353\n",
            "Epoch 13/25\n",
            "307/307 [==============================] - 118s 383ms/step - loss: 0.4281 - accuracy: 0.8512 - val_loss: 0.4966 - val_accuracy: 0.8294\n",
            "Epoch 14/25\n",
            "307/307 [==============================] - 121s 394ms/step - loss: 0.4096 - accuracy: 0.8577 - val_loss: 2.0133 - val_accuracy: 0.3832\n",
            "Epoch 15/25\n",
            "307/307 [==============================] - 118s 385ms/step - loss: 0.3976 - accuracy: 0.8652 - val_loss: 0.6059 - val_accuracy: 0.7838\n",
            "Epoch 16/25\n",
            "307/307 [==============================] - 123s 400ms/step - loss: 0.3878 - accuracy: 0.8686 - val_loss: 0.4918 - val_accuracy: 0.8196\n",
            "Epoch 17/25\n",
            "307/307 [==============================] - 120s 390ms/step - loss: 0.3588 - accuracy: 0.8798 - val_loss: 0.5195 - val_accuracy: 0.8137\n",
            "Epoch 18/25\n",
            "307/307 [==============================] - 118s 384ms/step - loss: 0.3482 - accuracy: 0.8787 - val_loss: 0.7465 - val_accuracy: 0.7449\n",
            "Epoch 19/25\n",
            "307/307 [==============================] - 118s 383ms/step - loss: 0.3440 - accuracy: 0.8810 - val_loss: 0.7710 - val_accuracy: 0.7269\n",
            "Epoch 20/25\n",
            "307/307 [==============================] - 118s 385ms/step - loss: 0.3167 - accuracy: 0.8940 - val_loss: 0.5071 - val_accuracy: 0.8234\n",
            "Epoch 21/25\n",
            "307/307 [==============================] - 120s 392ms/step - loss: 0.3125 - accuracy: 0.8950 - val_loss: 0.6381 - val_accuracy: 0.7829\n",
            "Epoch 22/25\n",
            "307/307 [==============================] - 117s 380ms/step - loss: 0.3082 - accuracy: 0.8962 - val_loss: 0.9778 - val_accuracy: 0.6820\n",
            "Epoch 23/25\n",
            "307/307 [==============================] - 117s 382ms/step - loss: 0.2900 - accuracy: 0.9039 - val_loss: 0.7253 - val_accuracy: 0.7442\n",
            "Epoch 24/25\n",
            "307/307 [==============================] - 117s 382ms/step - loss: 0.2784 - accuracy: 0.9087 - val_loss: 0.8478 - val_accuracy: 0.7124\n",
            "Epoch 25/25\n",
            "307/307 [==============================] - 117s 382ms/step - loss: 0.2596 - accuracy: 0.9096 - val_loss: 0.6463 - val_accuracy: 0.7905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad4040d950>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet.fit(training_set,\n",
        "          batch_size=128,\n",
        "          epochs=3,\n",
        "          verbose=1,\n",
        "          validation_data=val_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VszFo5Gr4L0y",
        "outputId": "cdbb761f-e99c-44b3-f8b6-4b0bd31c1754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "307/307 [==============================] - 123s 400ms/step - loss: 0.2605 - accuracy: 0.9123 - val_loss: 0.6824 - val_accuracy: 0.7667\n",
            "Epoch 2/3\n",
            "307/307 [==============================] - 121s 395ms/step - loss: 0.2406 - accuracy: 0.9175 - val_loss: 0.4733 - val_accuracy: 0.8403\n",
            "Epoch 3/3\n",
            "307/307 [==============================] - 116s 378ms/step - loss: 0.2360 - accuracy: 0.9196 - val_loss: 0.7735 - val_accuracy: 0.7430\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad40405490>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_VALID=val_set.n//val_set.batch_size\n",
        "AlexNet.evaluate_generator(generator=val_set,\n",
        "steps= STEP_SIZE_VALID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN-WCEmBleTS",
        "outputId": "37cf6100-b1f7-495b-9b4e-6e57fc3b25ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.77260422706604, 0.7437977194786072]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN=training_set.n//training_set.batch_size\n",
        "AlexNet.evaluate_generator(generator=training_set,\n",
        "steps=STEP_SIZE_TRAIN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydGCGuXbleRX",
        "outputId": "b2291728-0452-452c-b321-cf8c04a5e9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5438219308853149, 0.805657684803009]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "Name = []\n",
        "\n",
        "for img in glob.glob(test_dir):\n",
        "    prediction = AlexNet.predict_generator(test_set,steps=130,verbose=1)\n",
        "    for name in os.listdir('/content/drive/MyDrive/sprints project /testset/Scenes testing test'):\n",
        "         Name.append(name[0::])\n",
        "\n",
        "\n",
        "\n",
        "predicted_class_indics=np.argmax(prediction,axis=1)\n",
        "Name.sort()\n",
        "Temp = {'Image':Name, 'Label':predicted_class_indics}\n",
        "temp = pd.DataFrame(Temp)\n",
        "temp.to_csv('/content/results.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyEMVyALleO9",
        "outputId": "5c779748-0763-4b04-a909-51b95dc26aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 95/130 [====================>.........] - ETA: 3s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 130 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r130/130 [==============================] - 9s 71ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N62Iax-nleMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gsO3uQRtleJi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}